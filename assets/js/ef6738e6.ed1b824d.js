"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[8675],{3027:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"Benchmarking/gpu-benchmarking","title":"GPU Benchmarking","description":"CatP2P provides GPU benchmarking functionality to assess the compute capabilities of graphics processing units. This is essential for distributed applications that need to allocate GPU-intensive tasks efficiently.","source":"@site/docs/Benchmarking/gpu-benchmarking.md","sourceDirName":"Benchmarking","slug":"/Benchmarking/gpu-benchmarking","permalink":"/catp2p/docs/Benchmarking/gpu-benchmarking","draft":false,"unlisted":false,"editUrl":"https://github.com/johnnyvillas/catp2p/tree/main/docs-site/docs/Benchmarking/gpu-benchmarking.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Memory Benchmarking","permalink":"/catp2p/docs/Benchmarking/memory-benchmarking"}}');var t=i(4848),s=i(8453);const a={sidebar_position:3},l="GPU Benchmarking",c={},o=[{value:"Overview",id:"overview",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Simple Benchmark",id:"simple-benchmark",level:3},{value:"Getting GPU Information",id:"getting-gpu-information",level:3},{value:"Using the GPU Benchmark Context",id:"using-the-gpu-benchmark-context",level:3},{value:"Custom Benchmark Configuration",id:"custom-benchmark-configuration",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Analyzing Performance Scaling",id:"analyzing-performance-scaling",level:3},{value:"Visualizing Performance Results",id:"visualizing-performance-results",level:3},{value:"Determining Task Suitability",id:"determining-task-suitability",level:3},{value:"Understanding the Matrix Multiplication Benchmark",id:"understanding-the-matrix-multiplication-benchmark",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"API Reference",id:"api-reference",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"gpu-benchmarking",children:"GPU Benchmarking"})}),"\n",(0,t.jsx)(n.p,{children:"CatP2P provides GPU benchmarking functionality to assess the compute capabilities of graphics processing units. This is essential for distributed applications that need to allocate GPU-intensive tasks efficiently."}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"The GPU benchmarking module allows you to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Benchmark GPU compute performance using matrix multiplication"}),"\n",(0,t.jsx)(n.li,{children:"Get detailed information about the GPU"}),"\n",(0,t.jsx)(n.li,{children:"Compare performance across different graphics cards"}),"\n",(0,t.jsx)(n.li,{children:"Customize benchmark parameters"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,t.jsx)(n.h3,{id:"simple-benchmark",children:"Simple Benchmark"}),"\n",(0,t.jsx)(n.p,{children:"To run a simple GPU benchmark with default settings:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu;\nuse catp2p::error::Error;\n\nfn main() -> Result<(), Error> {\n    // Run a simple benchmark and get the overall score\n    let score = gpu::run_gpu_benchmark()?;\n    println!("GPU benchmark score: {:.2} MFLOPS", score);\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"getting-gpu-information",children:"Getting GPU Information"}),"\n",(0,t.jsx)(n.p,{children:"To get information about the GPU without running a benchmark:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu::get_gpu_info;\n\nfn main() -> Result<(), catp2p::error::Error> {\n    // Get GPU information\n    let gpu_info = get_gpu_info()?;\n    \n    println!("GPU: {} ({})", gpu_info.name, gpu_info.vendor);\n    println!("Driver: {}", gpu_info.driver);\n    println!("Estimated VRAM: {}", gpu_info.vram);\n    println!("Backend: {}", gpu_info.backend);\n    println!("Type: {}", if gpu_info.is_integrated { "Integrated" } else { "Discrete" });\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"using-the-gpu-benchmark-context",children:"Using the GPU Benchmark Context"}),"\n",(0,t.jsxs)(n.p,{children:["For more control and better performance, use the ",(0,t.jsx)(n.code,{children:"GpuBenchmarkContext"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu::GpuBenchmarkContext;\nuse std::time::Duration;\n\nfn main() -> Result<(), catp2p::error::Error> {\n    // Create a benchmark context\n    let context = GpuBenchmarkContext::new()?;\n    \n    println!("Testing GPU: {}", context.gpu_info.name);\n    \n    // Run matrix multiplication benchmark with different sizes\n    let sizes = [512, 1024, 2048];\n    \n    for &size in &sizes {\n        println!("Running benchmark with {}x{} matrices...", size, size);\n        \n        let result = context.run_matrix_mult(Duration::from_secs(3), size)?;\n        \n        println!("  Score: {:.2} MFLOPS", result.score);\n        println!("  Average FPS: {:.2}", result.average_fps);\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"custom-benchmark-configuration",children:"Custom Benchmark Configuration"}),"\n",(0,t.jsx)(n.p,{children:"To run a GPU benchmark with custom configuration:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu::{GpuBenchmarkConfig, run_gpu_benchmark_with_config};\n\nfn main() -> Result<(), catp2p::error::Error> {\n    // Create a custom configuration\n    let config = GpuBenchmarkConfig {\n        test_duration_secs: 5,           // Duration of each test in seconds\n        complexity: 8,                   // Higher complexity (larger matrices)\n        ..Default::default()\n    };\n    \n    // Run the benchmark with custom configuration\n    let result = run_gpu_benchmark_with_config(&config)?;\n    \n    println!("Benchmark results for {}:", result.gpu_model);\n    println!("  Compute Score: {:.2} MFLOPS", result.compute_score);\n    println!("  Overall Score: {:.2}", result.overall_score);\n    println!("  Average FPS: {:.2}", result.average_fps);\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,t.jsx)(n.h3,{id:"analyzing-performance-scaling",children:"Analyzing Performance Scaling"}),"\n",(0,t.jsx)(n.p,{children:"A common use case is to analyze how GPU performance scales with workload size:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu::GpuBenchmarkContext;\nuse std::time::Duration;\n\nfn main() -> Result<(), catp2p::error::Error> {\n    // Create a benchmark context\n    let context = GpuBenchmarkContext::new()?;\n    \n    // Run benchmarks with different complexity levels\n    let complexity_levels = [1, 3, 5, 8, 10];\n    let mut results = Vec::new();\n    \n    for &complexity in &complexity_levels {\n        // Calculate matrix size based on complexity\n        let matrix_size = 512 + (complexity * 128);\n        \n        println!("Testing {}x{} matrices...", matrix_size, matrix_size);\n        \n        let result = context.run_matrix_mult(Duration::from_secs(2), matrix_size)?;\n        \n        println!("  Score: {:.2} MFLOPS", result.score);\n        results.push((complexity, result.score));\n    }\n    \n    // Find optimal complexity for this GPU\n    if let Some(&(optimal_complexity, max_score)) = results.iter()\n        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal)) {\n        \n        println!("Optimal complexity for this GPU: {}", optimal_complexity);\n        println!("Peak performance: {:.2} MFLOPS", max_score);\n        \n        // Calculate optimal matrix size\n        let optimal_size = 512 + (optimal_complexity * 128);\n        println!("Optimal matrix size: {}x{}", optimal_size, optimal_size);\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"visualizing-performance-results",children:"Visualizing Performance Results"}),"\n",(0,t.jsx)(n.p,{children:"You can create a simple ASCII chart to visualize performance scaling:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'// After collecting results as (complexity, score) pairs:\nlet max_score = results.iter().map(|&(_, score)| score as usize).max().unwrap_or(1);\nlet scale = 50.0 / max_score as f64;\n\nprintln!("Performance scaling (higher is better):");\nfor &(complexity, score) in &results {\n    let bar_length = (score as f64 * scale) as usize;\n    let bar = "#".repeat(bar_length);\n    println!("Complexity {:2}: {:10.2} MFLOPS |{}|", complexity, score, bar);\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"determining-task-suitability",children:"Determining Task Suitability"}),"\n",(0,t.jsx)(n.p,{children:"You can use the benchmark results to determine if a GPU is suitable for specific tasks:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'use catp2p::benchmark::gpu::GpuBenchmarkContext;\nuse std::time::Duration;\n\nfn main() -> Result<(), catp2p::error::Error> {\n    // Create a benchmark context\n    let context = GpuBenchmarkContext::new()?;\n    \n    // Run a benchmark with a moderate workload\n    let matrix_size = 1024;\n    let result = context.run_matrix_mult(Duration::from_secs(3), matrix_size)?;\n    \n    println!("GPU: {}", context.gpu_info.name);\n    println!("Compute Score: {:.2} MFLOPS", result.score);\n    \n    // Determine suitability for different tasks\n    if result.score > 5_000_000.0 {\n        println!("This GPU is excellent for:");\n        println!("- Complex matrix operations");\n        println!("- Machine learning workloads");\n        println!("- Scientific simulations");\n    } else if result.score > 1_000_000.0 {\n        println!("This GPU is good for:");\n        println!("- Moderate matrix operations");\n        println!("- Basic machine learning tasks");\n        println!("- Data processing");\n    } else if result.score > 100_000.0 {\n        println!("This GPU has limited capabilities for:");\n        println!("- Simple matrix operations");\n        println!("- Basic data processing");\n    } else {\n        println!("This GPU is not recommended for compute tasks");\n        println!("Consider using CPU for these workloads instead");\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"understanding-the-matrix-multiplication-benchmark",children:"Understanding the Matrix Multiplication Benchmark"}),"\n",(0,t.jsx)(n.p,{children:"The matrix multiplication benchmark is a standard way to measure GPU compute performance:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What it measures"}),": How quickly the GPU can multiply two large matrices"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Why it matters"}),": Matrix multiplication is a fundamental operation in many GPU workloads:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Machine learning (neural network layers)"}),"\n",(0,t.jsx)(n.li,{children:"Scientific computing"}),"\n",(0,t.jsx)(n.li,{children:"Data processing"}),"\n",(0,t.jsx)(n.li,{children:"Computer graphics (transformations)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Two random matrices of size NxN are created"}),"\n",(0,t.jsx)(n.li,{children:"The matrices are uploaded to GPU memory"}),"\n",(0,t.jsx)(n.li,{children:"A compute shader multiplies the matrices"}),"\n",(0,t.jsx)(n.li,{children:"The process is repeated for the specified duration"}),"\n",(0,t.jsx)(n.li,{children:"Performance is measured in MFLOPS (Millions of Floating Point Operations Per Second)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Matrix size and complexity"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Matrix size is calculated as: 512 + (complexity * 128)"}),"\n",(0,t.jsx)(n.li,{children:"Complexity ranges from 1 to 10"}),"\n",(0,t.jsx)(n.li,{children:"Larger matrices provide more accurate results but may hit memory limits"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"GPU benchmarking can be resource-intensive and may temporarily impact system performance"}),"\n",(0,t.jsx)(n.li,{children:"For the most accurate results, close other GPU-intensive applications during benchmarking"}),"\n",(0,t.jsx)(n.li,{children:"Results may vary based on driver versions and system conditions"}),"\n",(0,t.jsx)(n.li,{children:"Performance can be affected by thermal throttling during extended tests"}),"\n",(0,t.jsx)(n.li,{children:"Different GPUs have different optimal workload sizes - a GPU might perform better with certain matrix sizes"}),"\n",(0,t.jsx)(n.li,{children:"The benchmark uses compute shaders, which may not be available on very old GPUs"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,t.jsxs)(n.p,{children:["The GPU benchmarking functions return ",(0,t.jsx)(n.code,{children:"Result<T, Error>"})," types, allowing you to handle errors gracefully:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'match GpuBenchmarkContext::new() {\n    Ok(context) => {\n        // Use the context for benchmarking\n    },\n    Err(e) => println!("GPU benchmarking not available: {}", e),\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Common errors include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"No compatible GPU found"}),"\n",(0,t.jsx)(n.li,{children:"Insufficient GPU capabilities for compute shaders"}),"\n",(0,t.jsx)(n.li,{children:"Driver or API compatibility issues"}),"\n",(0,t.jsx)(n.li,{children:"System resource limitations"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,t.jsxs)(n.p,{children:["For detailed API information, see the ",(0,t.jsx)(n.a,{href:"/catp2p/docs/api/benchmark/gpu",children:"GPU Benchmarking API Reference"}),"."]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var r=i(6540);const t={},s=r.createContext(t);function a(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);